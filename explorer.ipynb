{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZOP-Kg-CcFa"
      },
      "source": [
        "# Run in COLAB\n",
        "This notebook is made for being runned in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuW_kmAzCcFd",
        "outputId": "d6e197c3-4ec8-4d06-e7d4-a9f5195bb994"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install fiftyone\n",
        "!pip install fiftyone-db==0.4.3\n",
        "!pip install wandb\n",
        "\n",
        "%cd /content\n",
        "!git clone https://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@github.com/aslakdjupskas/STF.git\n",
        "!git pull\n",
        "!pip install compressai\n",
        "!pip install pybind11\n",
        "\n",
        "%cd /content/STF\n",
        "# Loading pretrained weights\n",
        "%mkdir -p compressai/pretrained && gdown -O compressai/pretrained/ 1OFzZoEaofNgsimBuOPHtgOJiGsR_RS-M\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!pip install -e '.[dev]'\n",
        "\n",
        "!git checkout devMorten\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rJUreJvCcFf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from our_utils import (pull_openimages,\n",
        "                       prepare_dataloader_from_folder,\n",
        "                       load_pretrained_model,\n",
        "                       plot_reconstruction)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_name = \"Project Image\"\n",
        "wandb_log = True\n",
        "log_image_every = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddoGw3lrCcFg"
      },
      "source": [
        "# Optimize compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Hg35PLCcFg"
      },
      "source": [
        "Do some setup and load model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLGcymMMCcFg",
        "outputId": "2dc2b0ea-a259-4088-80be-df25d6620f83"
      },
      "outputs": [],
      "source": [
        "# Some defenitions\n",
        "#!ls\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "focus_images_dir = \"focus_images\"\n",
        "evaluation_dir = \"openimages\"\n",
        "channels = 3\n",
        "test_batch_size = 5\n",
        "download_size = 5\n",
        "patch_size = (256, 256)\n",
        "\n",
        "# Prepare data and load model\n",
        "test_dataloader = prepare_dataloader_from_folder(patch_size=patch_size, test_batch_size=test_batch_size, device=device, dataset_dir=focus_images_dir)\n",
        "model = load_pretrained_model(path=\"compressai/pretrained/stf_0035_best.pth.tar\", device=device, freeze=True)\n",
        "\n",
        "our_batch = next(iter(test_dataloader))\n",
        "our_batch = our_batch.to(device)\n",
        "\n",
        "# Generate a normal reconstruction\n",
        "standard_compression = model.compress(our_batch)\n",
        "normal_reconstruction = model.decompress(*standard_compression.values())['x_hat']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOAnNLLzCcFh"
      },
      "source": [
        "# Compress by Optimizing y\n",
        "\n",
        "Compress by optimizing y. This is done by partially compressing the original image to obtain y, then optimizing y through the decoder to reconstruct the original image. Then y is further compressed into the normal compression format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sQuKiNK3CcFh",
        "outputId": "2abf0997-d13e-4729-d7da-da76f6b50f48"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-6\n",
        "wandb.init(project=project_name, config={\"learning_rate\": learning_rate})\n",
        "compression_by_y = model.optimized_compress(our_batch, iterations=10, normal_reconstruction=normal_reconstruction,\n",
        "                                     verbose=True, wandb_log=wandb_log, log_image_every=5)\n",
        "reconstructed_image_y_compression = model.decompress(*compression_by_y.values())['x_hat']\n",
        "\n",
        "# Plot the results\n",
        "plot_reconstruction(our_batch.cpu(), reconstructed_image_y_compression.cpu(), normal_reconstruction.cpu())\n",
        "# finish wandb run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcgVtbbyCcFh"
      },
      "source": [
        "# Decompress by Optimizing y_bar\n",
        "Decompress by optimizing y_bar. This is done by sending the reconstructed image through the encoder again, and then optimizing the resulting y_bar towards the y_bar gotten from the compression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBmYQk6tCcFh"
      },
      "source": [
        "First we decompress from a normal compression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ggOFWXciCcFh",
        "outputId": "7c80694f-991d-4291-f87b-2090465256ca"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "wandb.init(project=project_name, config={\"learning_rate\": learning_rate})\n",
        "reconstruction_by_y_bar_standar_compression = model.optimized_decompress(*standard_compression.values(), original_image=our_batch, iterations=10, normal_reconstruction=normal_reconstruction, \n",
        "                                                                              verbose=True, wandb_log=wandb_log, log_image_every=log_image_every, indication='Standard')['x_hat']\n",
        "plot_reconstruction(our_batch.cpu(), reconstruction_by_y_bar_standar_compression.cpu(), normal_reconstruction.cpu())\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJTgEEC5CcFi"
      },
      "source": [
        "Then we decompress from an optimized y-compression obtain from the section above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "U-4xoxcICcFi",
        "outputId": "09532cac-8196-4bd4-d689-7aa13142ab95"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "wandb.init(project=project_name, config={\"learning_rate\": learning_rate})\n",
        "reconstructed_by_bar_y_compression = model.optimized_decompress(*compression_by_y.values(), original_image=our_batch, \n",
        "                                                                normal_reconstruction=normal_reconstruction, iterations=10, \n",
        "                                                                wandb_log=wandb_log, log_image_every=5, verbose=True, indication=\"Optimized\",)['x_hat']\n",
        "plot_reconstruction(our_batch.cpu(), reconstructed_by_bar_y_compression.cpu(), normal_reconstruction.cpu())\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxESYFpACcFi"
      },
      "source": [
        "# Demonstrate potential of optimizing y_bar without quantization\n",
        "Optimize y_bar through encoder towards original image. This is not possible with quantization, and does not save as much space as quantization. It is more of a theoretical demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FVJ9zBSQCcFi",
        "outputId": "a31073f5-8d78-4d2d-b42c-49830663d9b1"
      },
      "outputs": [],
      "source": [
        "reconstruction_from_y_bar_optimization = model.y_bar_optimize_from_imagedecoder(*standard_compression.values(), iterations=1000, original_image=our_batch,\n",
        "                                                                                normal_reconstruction=normal_reconstruction, verbose=True)['x_hat']\n",
        "\n",
        "plot_reconstruction(our_batch.cpu(), reconstruction_from_y_bar_optimization.cpu(), normal_reconstruction.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpBQgD9fGKSV"
      },
      "source": [
        "# Run evaluation\n",
        "\n",
        "First download images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pull_openimages(traning_size=0, test_size=download_size, dataset_dir=evaluation_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Evaluate normal model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 -m compressai.utils.eval_model -d openimages/test/data -r /normal_reconstructions -a stf -p compressai/pretrained/stf_0035_best.pth.tar --cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Evaluating only compress optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 -m compressai.utils.eval_model -d openimages/test/data -r /compress_reconstructions -a stf_compress_optimizer -p compressai/pretrained/stf_0035_best.pth.tar --cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluating only decompress optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 -m compressai.utils.eval_model -d openimages/test/data -r /decompress_reconstructions -a stf_decompress_optimizer -p compressai/pretrained/stf_0035_best.pth.tar --cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluating both compress and decompress optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 -m compressai.utils.eval_model -d openimages/test/data -r /full_reconstructions -a stf_full_optimizer -p compressai/pretrained/stf_0035_best.pth.tar --cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Don't use our GPU when finished"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
